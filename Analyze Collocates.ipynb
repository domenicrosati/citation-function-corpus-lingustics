{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.collocations import *\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from ast import literal_eval as make_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval as make_tuple\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "def disputing_greater_flt(x):\n",
    "    return x['disputing_freq'] >=  x['supporting_freq'] and x['disputing_freq'] >=  x['mentioning_freq']\n",
    "\n",
    "def supporting_greater_flt(x):\n",
    "    return x['supporting_freq'] >=  x['disputing_freq'] and x['supporting_freq'] >=  x['disputing_freq']\n",
    "\n",
    "def mentioning_greater_flt(x):\n",
    "    return x['mentioning_freq'] >=  x['disputing_freq'] and x['mentioning_freq'] >=  x['supporting_freq']\n",
    "\n",
    "\n",
    "def common_flt(x):\n",
    "    return x['supporting_disputing_loglikelihood'] <= 3.84 and x['supporting_mentioning_loglikelihood'] <= 3.84\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def make_pos(x, pos):\n",
    "    tup = make_tuple(x)\n",
    "    tokenized = nltk.word_tokenize(' '.join(tup))\n",
    "    tags = nltk.pos_tag(tokenized)\n",
    "    tagstr = ''\n",
    "    for tag in tags:\n",
    "        tagstr += tag[1] + ' '\n",
    "    return tagstr\n",
    "    \n",
    "def find_pos(x, pos):\n",
    "    tup = make_tuple(x)\n",
    "    tokenized = nltk.word_tokenize(' '.join(tup))\n",
    "    tags = nltk.pos_tag(tokenized)\n",
    "    for tag in tags:\n",
    "        if tag[1] == pos:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def sentiment(x):\n",
    "    tup = make_tuple(x)\n",
    "    sent = sia.polarity_scores(' '.join(tup))\n",
    "    return sent['compound']\n",
    "\n",
    "def discourse_markers(x):\n",
    "    tup = make_tuple(x)\n",
    "    sent = ' '.join(tup)\n",
    "    for dm in DISCOURSE_MARKERS:\n",
    "        if dm in sent:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_pos = ['RB','RBR', 'RBS', 'JJ', 'JJR', 'JJS', 'IN', 'CC']\n",
    "POS = {\n",
    "    \"CC\": \"coordinating conjunctions\",\n",
    "    \"IN\": \"prepositions and subordinating conjunctions\",\n",
    "    \"JJ\": \"adjectives\",\n",
    "    \"JJR\": \"adjectives, comparative\",\n",
    "    \"JJS\": \"adjectives, superlative\",\n",
    "    \"RB\": \"adverbs\",\n",
    "    \"RBR\": \"adverbs, comparative\",\n",
    "    \"RBS\": \"adverbs, superlative\"\n",
    "}\n",
    "\n",
    "analysize = ['bigrams', 'trigrams']\n",
    "for analysis in analysize:\n",
    "    for pos in interesting_pos:\n",
    "        supporting_counts = []\n",
    "        disputing_counts = []\n",
    "        mentioning_counts = []\n",
    "        df = pd.read_csv(f\"./analysis/{analysis}_supporting_greater.csv\")\n",
    "        of = df[df.apply(lambda x: find_pos(x[analysis], pos), axis=1)]\n",
    "        of.to_csv(f\"./analysis/{analysis}_{pos}_supporting_greater.csv\")\n",
    "        supporting_counts.append(len(of) / len(df))\n",
    "        print(f\"supporting - {analysis} - {pos}: {len(of) / len(df)} \")\n",
    "\n",
    "        df = pd.read_csv(f\"./analysis/{analysis}_disputing_greater.csv\")\n",
    "        of = df[df.apply(lambda x: find_pos(x[analysis], pos), axis=1)]\n",
    "        of.to_csv(f\"./analysis/{analysis}_{pos}_disputing_greater.csv\")\n",
    "        disputing_counts.append(len(of) / len(df))\n",
    "        print(f\"disputing - {analysis} - {pos}: {len(of) / len(df)} \")\n",
    "        \n",
    "\n",
    "        df = pd.read_csv(f\"./analysis/{analysis}_mentioning_greater.csv\") # it should be mentioning greater than both\n",
    "        of = df[df.apply(lambda x: find_pos(x[analysis], pos), axis=1)]\n",
    "        of.to_csv(f\"./analysis/{analysis}_{pos}_mentioning_greater.csv\")\n",
    "        mentioning_counts.append(len(of) / len(df))\n",
    "        print(f\"mentioning - {analysis} - {pos}: {len(of) / len(df)} \")\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'Factor': pos,\n",
    "            'Supporting citations': supporting_counts,\n",
    "            'Disputing citations': disputing_counts,\n",
    "            'Mentioning citations': mentioning_counts,\n",
    "        })\n",
    "        fig, ax1 = pyplot.subplots(figsize=(10, 10))\n",
    "        tidy = df.melt(id_vars='Factor').rename(columns=str.title)\n",
    "        sns.barplot(x='Factor', y='Value', hue='Variable', data=tidy, ax=ax1)\n",
    "        ax1.set(title=f\"Frequency of {POS[pos]} ({pos}) in {analysis} (%)\", xlabel=f\"Part of speech: {POS[pos]}\", ylabel=f\"Frequency of occurance(%)\")\n",
    "        vals = ax1.get_yticks()\n",
    "        ax1.set_yticklabels(['{:,.2%}'.format(x) for x in vals])\n",
    "        sns.despine(fig)\n",
    "        pyplot.savefig(f'./analysis/{analysis}_{pos}.png')\n",
    "        pyplot.plot()\n",
    "\n",
    "# bar and counts of discourse markers\n",
    "# plot sentiments and correlates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysize = ['bigrams', 'trigrams']\n",
    "functions = [\n",
    "    {\n",
    "        'name': 'Supporting',\n",
    "        'type': 'supporting_greater',\n",
    "        'function': 'supporting_disputing_loglikelihood'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Disputing',\n",
    "        'type': 'disputing_greater',\n",
    "        'function': 'supporting_disputing_loglikelihood'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Mentioning',\n",
    "        'type': 'mentioning_greater',\n",
    "        'function': 'supporting_mentioning_loglikelihood'\n",
    "    }\n",
    "]\n",
    "for analysis in analysize:\n",
    "    for function in functions:\n",
    "        cite_type = function[\"type\"]\n",
    "        df = pd.read_csv(f\"./analysis/{analysis}_{cite_type}.csv\")\n",
    "        df['sent'] = df.apply(lambda x: sentiment(x[analysis]), axis=1)\n",
    "        print(function['name'])\n",
    "        print(df[['sent', function['function']]].corr(method = 'pearson'))\n",
    "        df.sort_values('sent').to_csv(f\"./analysis/{analysis}_{cite_type}_sent.csv\")\n",
    "\n",
    "        fig, ax1 = pyplot.subplots(figsize=(10, 10))\n",
    "        sns.scatterplot(data=df, x='sent', y=function['function'], ax=ax1)\n",
    "        ax1.set(title=f\"{function['name']} {analysis} sentiment versus log likelihood\", ylabel=\"Log Likelihood\", xlabel=f\"Sentiment (-1 negative, 0 neutral, 1 positive)\")\n",
    "        vals = ax1.get_yticks()\n",
    "        sns.despine(fig)\n",
    "        cite_name = function['type']\n",
    "        pyplot.savefig(f'./analysis/{analysis}_{cite_name}_sent_scatter.png')\n",
    "        pyplot.plot()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(x):\n",
    "    tup = make_tuple(x)\n",
    "    sent = TextBlob(' '.join(tup)).sentiment\n",
    "    return sent[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysize = ['bigrams', 'trigrams']\n",
    "functions = [\n",
    "    {\n",
    "        'name': 'Supporting',\n",
    "        'type': 'supporting_greater',\n",
    "        'function': 'supporting_disputing_loglikelihood'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Disputing',\n",
    "        'type': 'disputing_greater',\n",
    "        'function': 'supporting_disputing_loglikelihood'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Mentioning',\n",
    "        'type': 'mentioning_greater',\n",
    "        'function': 'supporting_mentioning_loglikelihood'\n",
    "    }\n",
    "]\n",
    "for analysis in analysize:\n",
    "    for function in functions:\n",
    "        cite_type = function[\"type\"]\n",
    "        df = pd.read_csv(f\"./analysis/{analysis}_{cite_type}.csv\")\n",
    "        df['subj'] = df.apply(lambda x: subjectivity(x[analysis]), axis=1)\n",
    "        print(function['name'])\n",
    "        print(df[['subj', function['function']]].corr(method = 'pearson'))\n",
    "        df.sort_values('subj').to_csv(f\"./analysis/{analysis}_{cite_type}_subj.csv\")\n",
    "\n",
    "        fig, ax1 = pyplot.subplots(figsize=(10, 10))\n",
    "        sns.histplot(data=df, x='subj', ax=ax1)\n",
    "        ax1.set(title=f\"{function['name']} {analysis} subjectivity\", xlabel=f\"Count of {analysis}\", ylabel=f\"Subjectivity (0.0 very objective, 1.0 very subjective)\")\n",
    "        vals = ax1.get_yticks()\n",
    "        sns.despine(fig)\n",
    "        cite_name = function['type']\n",
    "        pyplot.savefig(f'./analysis/{analysis}_{cite_name}_hist_plot.png')\n",
    "        pyplot.plot()\n",
    "        \n",
    "        fig, ax1 = pyplot.subplots(figsize=(10, 10))\n",
    "        sns.scatterplot(data=df, x='subj', y=function['function'], ax=ax1)\n",
    "        ax1.set(title=f\"{function['name']} {analysis} subjectivity versus log likelihood\", ylabel=\"Log Likelihood\", xlabel=f\"Subjectivity (0.0 very objective, 1.0 very subjective)\")\n",
    "        vals = ax1.get_yticks()\n",
    "        sns.despine(fig)\n",
    "        cite_name = function['type']\n",
    "        pyplot.savefig(f'./analysis/{analysis}_{cite_name}_subj_scatter.png')\n",
    "        pyplot.plot()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
